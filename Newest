import pandas as pd
import os

def collect_unique_columns(excel_file):
    """
    Collects all unique column names from the second row across all sheets.
    
    Parameters:
        excel_file (str): Path to the input Excel file.
    
    Returns:
        list: Sorted list of unique column names.
    """
    # Load the Excel file
    xls = pd.ExcelFile(excel_file)
    unique_columns = set()

    for sheet in xls.sheet_names:
        try:
            # Read the first two rows to access the second row headers
            df = pd.read_excel(excel_file, sheet_name=sheet, header=None, nrows=2)
        except Exception as e:
            print(f"Error reading sheet '{sheet}': {e}. Skipping this sheet.")
            continue

        if df.empty or len(df) < 2:
            print(f"Sheet '{sheet}' does not have enough rows. Skipping this sheet.")
            continue

        # Get columns from the second row (index 1), starting from the second column (B)
        columns = df.iloc[1, 1:]  # Skip A2 which is 'strategy'
        # Drop NaN values, convert to string, strip whitespace, and collect as list
        columns = columns.dropna().astype(str).str.strip().tolist()
        unique_columns.update(columns)

    return sorted(unique_columns)

def collect_data_for_year(excel_file, year, unique_columns):
    """
    Collects data for the specified year from each sheet.
    Missing columns are filled with 0.
    
    Parameters:
        excel_file (str): Path to the input Excel file.
        year (str or int): The year for which data needs to be collected.
        unique_columns (list): List of unique column names across all sheets.
    
    Returns:
        pd.DataFrame: Consolidated DataFrame with data from all sheets for the specified year.
    """
    xls = pd.ExcelFile(excel_file)
    data_rows = []

    for sheet in xls.sheet_names:
        try:
            # Read the sheet with header in the second row
            df = pd.read_excel(excel_file, sheet_name=sheet, header=1)  # header=1 sets row 2 as header
        except Exception as e:
            print(f"Error reading sheet '{sheet}': {e}. Skipping this sheet.")
            continue

        # Check if 'strategy' column exists (case-insensitive)
        strategy_cols = [col for col in df.columns if str(col).strip().lower() == 'strategy']
        if not strategy_cols:
            print(f"'strategy' column not found in sheet: '{sheet}'. Skipping this sheet.")
            continue

        # Assume the first 'strategy' column is the relevant one
        strategy_col = strategy_cols[0]

        # Set 'strategy' as the index
        df.set_index(strategy_col, inplace=True)

        # Normalize year format based on the index type
        if pd.api.types.is_numeric_dtype(df.index):
            try:
                year_key = float(year) if isinstance(year, str) and '.' in year else int(year)
            except ValueError:
                print(f"Year '{year}' is not compatible with sheet '{sheet}' index type. Skipping this sheet.")
                continue
        else:
            year_key = str(year).strip()

        # Check if the specified year exists in the 'strategy' index
        if year_key in df.index:
            row = df.loc[year_key]
            # Create a dictionary with unique columns, fill missing with 0
            data = {col: row.get(col, 0) if pd.notna(row.get(col, 0)) else 0 for col in unique_columns}
            # Add an identifier for the sheet
            data['Sheet Name'] = sheet
            data_rows.append(data)
        else:
            print(f"Year '{year}' not found in sheet: '{sheet}'. Skipping this sheet.")

    if not data_rows:
        print("No data collected for the specified year across all sheets.")
        return pd.DataFrame()  # Return empty DataFrame

    # Create a DataFrame from the collected data
    result_df = pd.DataFrame(data_rows)

    # Replace any remaining NaN with 0 (additional safety)
    result_df.fillna(0, inplace=True)

    # Reorder columns to have 'Sheet Name' first
    cols = ['Sheet Name'] + [col for col in unique_columns]
    result_df = result_df[cols]

    return result_df

def main():
    # ================================
    # === Configuration Parameters ===
    # ================================

    # Path to the input Excel file
    # Replace with your actual file path. Use raw strings (r"") or double backslashes (\\) for Windows paths.
    input_file = r"C:\Path\To\Your\Input_File.xlsx"

    # Year for which data needs to be collected
    # Ensure that the year format matches the 'strategy' column in your Excel sheets
    year = "2023"  # Example: "2023" or 2023

    # Path for the output Excel file
    # The script will overwrite the file if it already exists
    output_file = r"C:\Path\To\Your\Output_File.xlsx"

    # ================================
    # === End of Configuration =======
    # ================================

    # Validate input file existence
    if not os.path.isfile(input_file):
        print(f"Input file '{input_file}' does not exist. Please check the path.")
        return

    # Collect unique columns
    print("Collecting unique column names from all sheets...")
    unique_cols = collect_unique_columns(input_file)
    print(f"Unique columns found: {unique_cols}")

    # Collect data for the specified year
    print(f"Collecting data for the year '{year}'...")
    consolidated_data = collect_data_for_year(input_file, year, unique_cols)

    if consolidated_data.empty:
        print("No data found for the specified year across all sheets. No output file created.")
        return

    # Write the consolidated data to a new Excel file
    try:
        consolidated_data.to_excel(output_file, index=False)
        print(f"Data successfully written to '{output_file}'")
    except Exception as e:
        print(f"Failed to write to output file '{output_file}': {e}")

if __name__ == "__main__":
    main()
